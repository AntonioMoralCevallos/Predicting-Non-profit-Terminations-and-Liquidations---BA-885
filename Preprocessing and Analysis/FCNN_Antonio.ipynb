{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d7e05e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-22 13:57:58.628396: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-22 13:57:58.628441: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %tensorflow_version 2.x # << This line comes before the import \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0346312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_yrs_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2ba6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 266387 entries, 0 to 266386\n",
      "Columns: 545 entries, ein to y_TL\n",
      "dtypes: float64(218), int64(327)\n",
      "memory usage: 1.1 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffce032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('ein',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "267ac574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unrelbusinccd</th>\n",
       "      <th>initiationfees</th>\n",
       "      <th>grsrcptspublicuse</th>\n",
       "      <th>grsincmembers</th>\n",
       "      <th>grsincother</th>\n",
       "      <th>totcntrbgfts</th>\n",
       "      <th>totprgmrevnue</th>\n",
       "      <th>invstmntinc</th>\n",
       "      <th>txexmptbndsproceeds</th>\n",
       "      <th>royaltsinc</th>\n",
       "      <th>...</th>\n",
       "      <th>nonpfreayr-1_8</th>\n",
       "      <th>nonpfreayr-1_9</th>\n",
       "      <th>nonpfreayr-1_11</th>\n",
       "      <th>nonpfreayr-1_12</th>\n",
       "      <th>nonpfreayr-1_13</th>\n",
       "      <th>nonpfreayr-1_14</th>\n",
       "      <th>nonpfreayr-1_15</th>\n",
       "      <th>y_term</th>\n",
       "      <th>y_liq</th>\n",
       "      <th>y_TL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>935508</td>\n",
       "      <td>120315</td>\n",
       "      <td>7456</td>\n",
       "      <td>19969</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5050020</td>\n",
       "      <td>153784</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2945</td>\n",
       "      <td>11440</td>\n",
       "      <td>489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>220425</td>\n",
       "      <td>468101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>411058</td>\n",
       "      <td>2668044</td>\n",
       "      <td>29316</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>735052</td>\n",
       "      <td>783</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 544 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unrelbusinccd  initiationfees  grsrcptspublicuse  grsincmembers  \\\n",
       "0              0               0                  0              0   \n",
       "1              0               0                  0              0   \n",
       "2              0               0                  0              0   \n",
       "3              1          220425             468101              0   \n",
       "4              0               0                  0              0   \n",
       "\n",
       "   grsincother  totcntrbgfts  totprgmrevnue  invstmntinc  txexmptbndsproceeds  \\\n",
       "0            0        935508         120315         7456                19969   \n",
       "1            0             0        5050020       153784                    0   \n",
       "2            0          2945          11440          489                    0   \n",
       "3            0        411058        2668044        29316                    0   \n",
       "4            0            75         735052          783                    0   \n",
       "\n",
       "   royaltsinc  ...  nonpfreayr-1_8  nonpfreayr-1_9  nonpfreayr-1_11  \\\n",
       "0           0  ...               0               0                0   \n",
       "1           0  ...               0               0                0   \n",
       "2           0  ...               0               0                0   \n",
       "3           0  ...               0               0                0   \n",
       "4           0  ...               0               0                0   \n",
       "\n",
       "   nonpfreayr-1_12  nonpfreayr-1_13  nonpfreayr-1_14  nonpfreayr-1_15  y_term  \\\n",
       "0                0                0                0                0       0   \n",
       "1                0                0                0                0       0   \n",
       "2                0                0                0                0       0   \n",
       "3                0                0                0                0       0   \n",
       "4                0                0                0                0       0   \n",
       "\n",
       "   y_liq  y_TL  \n",
       "0      0     0  \n",
       "1      0     0  \n",
       "2      0     0  \n",
       "3      0     0  \n",
       "4      0     0  \n",
       "\n",
       "[5 rows x 544 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee038b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unrelbusinccd</th>\n",
       "      <th>initiationfees</th>\n",
       "      <th>grsrcptspublicuse</th>\n",
       "      <th>grsincmembers</th>\n",
       "      <th>grsincother</th>\n",
       "      <th>totcntrbgfts</th>\n",
       "      <th>totprgmrevnue</th>\n",
       "      <th>invstmntinc</th>\n",
       "      <th>txexmptbndsproceeds</th>\n",
       "      <th>royaltsinc</th>\n",
       "      <th>...</th>\n",
       "      <th>nonpfreayr-1_8</th>\n",
       "      <th>nonpfreayr-1_9</th>\n",
       "      <th>nonpfreayr-1_11</th>\n",
       "      <th>nonpfreayr-1_12</th>\n",
       "      <th>nonpfreayr-1_13</th>\n",
       "      <th>nonpfreayr-1_14</th>\n",
       "      <th>nonpfreayr-1_15</th>\n",
       "      <th>y_term</th>\n",
       "      <th>y_liq</th>\n",
       "      <th>y_TL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>266387.000000</td>\n",
       "      <td>2.663870e+05</td>\n",
       "      <td>2.663870e+05</td>\n",
       "      <td>2.663870e+05</td>\n",
       "      <td>2.663870e+05</td>\n",
       "      <td>2.663870e+05</td>\n",
       "      <td>2.663870e+05</td>\n",
       "      <td>2.663870e+05</td>\n",
       "      <td>2.663870e+05</td>\n",
       "      <td>2.663870e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>266387.000000</td>\n",
       "      <td>266387.000000</td>\n",
       "      <td>266387.000000</td>\n",
       "      <td>266387.000000</td>\n",
       "      <td>266387.000000</td>\n",
       "      <td>266387.000000</td>\n",
       "      <td>266387.000000</td>\n",
       "      <td>266387.000000</td>\n",
       "      <td>266387.000000</td>\n",
       "      <td>266387.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104284</td>\n",
       "      <td>3.665848e+03</td>\n",
       "      <td>3.186620e+03</td>\n",
       "      <td>2.158111e+05</td>\n",
       "      <td>6.919431e+03</td>\n",
       "      <td>1.568499e+06</td>\n",
       "      <td>5.910035e+06</td>\n",
       "      <td>1.649631e+05</td>\n",
       "      <td>7.404849e+02</td>\n",
       "      <td>2.067959e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.268238</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.028421</td>\n",
       "      <td>0.009486</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.009036</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.013544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305630</td>\n",
       "      <td>9.193288e+04</td>\n",
       "      <td>6.970756e+04</td>\n",
       "      <td>7.335869e+06</td>\n",
       "      <td>3.889358e+05</td>\n",
       "      <td>6.364980e+07</td>\n",
       "      <td>1.155329e+08</td>\n",
       "      <td>5.508513e+06</td>\n",
       "      <td>6.609736e+04</td>\n",
       "      <td>2.009176e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068122</td>\n",
       "      <td>0.443043</td>\n",
       "      <td>0.030375</td>\n",
       "      <td>0.166173</td>\n",
       "      <td>0.096934</td>\n",
       "      <td>0.096324</td>\n",
       "      <td>0.094626</td>\n",
       "      <td>0.072073</td>\n",
       "      <td>0.094020</td>\n",
       "      <td>0.115589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.975000e+03</td>\n",
       "      <td>-2.592000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.318009e+07</td>\n",
       "      <td>-2.173370e+05</td>\n",
       "      <td>-1.226788e+08</td>\n",
       "      <td>-8.238400e+07</td>\n",
       "      <td>-6.791210e+05</td>\n",
       "      <td>-3.222000e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.424500e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.133400e+04</td>\n",
       "      <td>7.967100e+04</td>\n",
       "      <td>3.690000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.402395e+05</td>\n",
       "      <td>5.366945e+05</td>\n",
       "      <td>8.787500e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.744288e+07</td>\n",
       "      <td>1.427130e+07</td>\n",
       "      <td>1.197840e+09</td>\n",
       "      <td>1.083687e+08</td>\n",
       "      <td>3.082145e+10</td>\n",
       "      <td>4.223764e+10</td>\n",
       "      <td>1.748190e+09</td>\n",
       "      <td>1.956747e+07</td>\n",
       "      <td>7.625538e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 544 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unrelbusinccd  initiationfees  grsrcptspublicuse  grsincmembers  \\\n",
       "count  266387.000000    2.663870e+05       2.663870e+05   2.663870e+05   \n",
       "mean        0.104284    3.665848e+03       3.186620e+03   2.158111e+05   \n",
       "std         0.305630    9.193288e+04       6.970756e+04   7.335869e+06   \n",
       "min         0.000000   -6.975000e+03      -2.592000e+03   0.000000e+00   \n",
       "25%         0.000000    0.000000e+00       0.000000e+00   0.000000e+00   \n",
       "50%         0.000000    0.000000e+00       0.000000e+00   0.000000e+00   \n",
       "75%         0.000000    0.000000e+00       0.000000e+00   0.000000e+00   \n",
       "max         1.000000    1.744288e+07       1.427130e+07   1.197840e+09   \n",
       "\n",
       "        grsincother  totcntrbgfts  totprgmrevnue   invstmntinc  \\\n",
       "count  2.663870e+05  2.663870e+05   2.663870e+05  2.663870e+05   \n",
       "mean   6.919431e+03  1.568499e+06   5.910035e+06  1.649631e+05   \n",
       "std    3.889358e+05  6.364980e+07   1.155329e+08  5.508513e+06   \n",
       "min   -2.318009e+07 -2.173370e+05  -1.226788e+08 -8.238400e+07   \n",
       "25%    0.000000e+00  1.424500e+03   0.000000e+00  4.000000e+00   \n",
       "50%    0.000000e+00  9.133400e+04   7.967100e+04  3.690000e+02   \n",
       "75%    0.000000e+00  4.402395e+05   5.366945e+05  8.787500e+03   \n",
       "max    1.083687e+08  3.082145e+10   4.223764e+10  1.748190e+09   \n",
       "\n",
       "       txexmptbndsproceeds    royaltsinc  ...  nonpfreayr-1_8  nonpfreayr-1_9  \\\n",
       "count         2.663870e+05  2.663870e+05  ...   266387.000000   266387.000000   \n",
       "mean          7.404849e+02  2.067959e+04  ...        0.004662        0.268238   \n",
       "std           6.609736e+04  2.009176e+06  ...        0.068122        0.443043   \n",
       "min          -6.791210e+05 -3.222000e+04  ...        0.000000        0.000000   \n",
       "25%           0.000000e+00  0.000000e+00  ...        0.000000        0.000000   \n",
       "50%           0.000000e+00  0.000000e+00  ...        0.000000        0.000000   \n",
       "75%           0.000000e+00  0.000000e+00  ...        0.000000        1.000000   \n",
       "max           1.956747e+07  7.625538e+08  ...        1.000000        1.000000   \n",
       "\n",
       "       nonpfreayr-1_11  nonpfreayr-1_12  nonpfreayr-1_13  nonpfreayr-1_14  \\\n",
       "count    266387.000000    266387.000000    266387.000000    266387.000000   \n",
       "mean          0.000923         0.028421         0.009486         0.009366   \n",
       "std           0.030375         0.166173         0.096934         0.096324   \n",
       "min           0.000000         0.000000         0.000000         0.000000   \n",
       "25%           0.000000         0.000000         0.000000         0.000000   \n",
       "50%           0.000000         0.000000         0.000000         0.000000   \n",
       "75%           0.000000         0.000000         0.000000         0.000000   \n",
       "max           1.000000         1.000000         1.000000         1.000000   \n",
       "\n",
       "       nonpfreayr-1_15         y_term          y_liq           y_TL  \n",
       "count    266387.000000  266387.000000  266387.000000  266387.000000  \n",
       "mean          0.009036       0.005222       0.008919       0.013544  \n",
       "std           0.094626       0.072073       0.094020       0.115589  \n",
       "min           0.000000       0.000000       0.000000       0.000000  \n",
       "25%           0.000000       0.000000       0.000000       0.000000  \n",
       "50%           0.000000       0.000000       0.000000       0.000000  \n",
       "75%           0.000000       0.000000       0.000000       0.000000  \n",
       "max           1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 544 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12ba4bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 228181 entries, 1 to 266386\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   y_term  228181 non-null  int64\n",
      " 1   y_liq   228181 non-null  int64\n",
      " 2   y_TL    228181 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 7.0 MB\n"
     ]
    }
   ],
   "source": [
    "df[['y_term','y_liq','y_TL']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d0d6e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228181, 544)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5201254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((228181, 541), (228181, 3))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cols = ['y_term', 'y_liq', 'y_TL']\n",
    "X = df.drop(columns = y_cols)\n",
    "y = df[y_cols]\n",
    "\n",
    "y1 = y['y_TL'].astype('category') # y1 - y full/partial \n",
    "yt = y['y_term'].astype('category') # yt - y term (full termination)\n",
    "yl = y['y_liq'].astype('category')  # yl - y liquid (partial liquidation)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb987631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((182544, 541), (45637, 541), (182544,), (45637,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3237512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-train, train-test split\n",
    "X_input, X_val, y_input, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9118d834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fully connected model\n",
    "fc_model = tf.keras.Sequential([tf.keras.layers.Dense(100,activation='tanh',input_shape = (541,)),\n",
    "    tf.keras.layers.Dense(50, activation='tanh'),\n",
    "    tf.keras.layers.Dense(1,activation = 'sigmoid'),\n",
    "    #tf.keras.layers.Softmax()\n",
    "    \n",
    "])\n",
    "\n",
    "lrate = 0.005\n",
    "fc_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
    "                     loss='binary_crossentropy' ,metrics=['accuracy','FalseNegatives'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b16f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc305d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, feature, label, val_feature, val_label, epochs, batch_size):\n",
    "  es = EarlyStopping(monitor='val_accuracy', \n",
    "                                   mode='max', \n",
    "                                   patience=10,\n",
    "                                   restore_best_weights=True)\n",
    "  history = model.fit(x=feature,\n",
    "                      y=label,\n",
    "                      validation_data=(val_feature, val_label),\n",
    "                      callbacks=[es],\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs)\n",
    "\n",
    "  trained_weight = model.get_weights()[0]\n",
    "  trained_bias = model.get_weights()[1]\n",
    "\n",
    "  epochs = history.epoch\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  accuracy = hist[\"accuracy\"]\n",
    "  val_accuracy = hist['val_accuracy']\n",
    "  return trained_weight, trained_bias, epochs, accuracy, val_accuracy, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "056089e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146035,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b85e48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146035, 541)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "917b4806",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_input = np.asarray(y_input).astype('float32').reshape((-1,1))\n",
    "y_val = np.asarray(y_val).astype('float32').reshape((-1,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7326267e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146035,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2991f893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36509, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d678b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 100)               54200     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 102       \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 59,352\n",
      "Trainable params: 59,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94fbeb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "147/147 [==============================] - 2s 8ms/step - loss: 0.0850 - accuracy: 0.9824 - false_negatives: 2042.0000 - val_loss: 0.0741 - val_accuracy: 0.9860 - val_false_negatives: 508.0000\n",
      "Epoch 2/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0738 - accuracy: 0.9859 - false_negatives: 2047.0000 - val_loss: 0.0731 - val_accuracy: 0.9860 - val_false_negatives: 508.0000\n",
      "Epoch 3/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0734 - accuracy: 0.9859 - false_negatives: 2047.0000 - val_loss: 0.0731 - val_accuracy: 0.9861 - val_false_negatives: 508.0000\n",
      "Epoch 4/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0735 - accuracy: 0.9859 - false_negatives: 2047.0000 - val_loss: 0.0732 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 5/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0733 - accuracy: 0.9859 - false_negatives: 2047.0000 - val_loss: 0.0727 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 6/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0731 - accuracy: 0.9859 - false_negatives: 2047.0000 - val_loss: 0.0725 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 7/30\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 0.0731 - accuracy: 0.9859 - false_negatives: 2047.0000 - val_loss: 0.0726 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 8/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0732 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0726 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 9/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0730 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0734 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 10/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0729 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0723 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 11/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0728 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0725 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 12/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0729 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0726 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 13/30\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 0.0729 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0724 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 14/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0728 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0725 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 15/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0728 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0753 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 16/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0731 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0728 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 17/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0730 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0726 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 18/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0728 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0726 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 19/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0728 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0729 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 20/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0728 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0727 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 21/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0730 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0726 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 22/30\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 0.0730 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0729 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 23/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0730 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0742 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 24/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0730 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0730 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 25/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0729 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0725 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 26/30\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 0.0728 - accuracy: 0.9860 - false_negatives: 2045.0000 - val_loss: 0.0725 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 27/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0730 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0726 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 28/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0730 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0733 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 29/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0735 - accuracy: 0.9860 - false_negatives: 2045.0000 - val_loss: 0.0733 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 30/30\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 0.0734 - accuracy: 0.9860 - false_negatives: 2045.0000 - val_loss: 0.0732 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "epochs = 30\n",
    "hist = fc_model.fit(x= X_input,\n",
    "                      y= y_input,\n",
    "                      validation_data=(X_val, y_val),\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3ffd126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0734 - accuracy: 0.9860 - false_negatives: 2044.0000 - val_loss: 0.0730 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 2/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0731 - accuracy: 0.9860 - false_negatives: 2045.0000 - val_loss: 0.0729 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 3/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0732 - accuracy: 0.9860 - false_negatives: 2045.0000 - val_loss: 0.0745 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 4/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0730 - accuracy: 0.9860 - false_negatives: 2045.0000 - val_loss: 0.0737 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 5/30\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 0.0731 - accuracy: 0.9860 - false_negatives: 2043.0000 - val_loss: 0.0729 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 6/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0731 - accuracy: 0.9860 - false_negatives: 2044.0000 - val_loss: 0.0756 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 7/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0733 - accuracy: 0.9860 - false_negatives: 2045.0000 - val_loss: 0.0733 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 8/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0731 - accuracy: 0.9860 - false_negatives: 2044.0000 - val_loss: 0.0732 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 9/30\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 0.0734 - accuracy: 0.9860 - false_negatives: 2045.0000 - val_loss: 0.0751 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 10/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0735 - accuracy: 0.9860 - false_negatives: 2044.0000 - val_loss: 0.0743 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 11/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0733 - accuracy: 0.9860 - false_negatives: 2045.0000 - val_loss: 0.0730 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 12/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0731 - accuracy: 0.9860 - false_negatives: 2046.0000 - val_loss: 0.0728 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n",
      "Epoch 13/30\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 0.0731 - accuracy: 0.9860 - false_negatives: 2044.0000 - val_loss: 0.0728 - val_accuracy: 0.9860 - val_false_negatives: 509.0000\n"
     ]
    }
   ],
   "source": [
    "trained_weight, trained_bias, epochs, accuracy, val_accuracy, hist = train_model(fc_model, X_input, y_input, X_val, y_val, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57e3c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_the_accuracy(epochs, accuracy, val_accuracy):\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Accuracy\")\n",
    "  plt.plot(epochs, accuracy, 'o-', label='train')\n",
    "  plt.plot(epochs, val_accuracy, 'o-', label='validation')\n",
    "  plt.legend()\n",
    "  plt.ylim([accuracy.min()*0.97, accuracy.max()])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "20a728a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_the_accuracy(epochs,accuracy,val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5dd1a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185494    1\n",
       "264384    1\n",
       "204715    1\n",
       "229221    1\n",
       "170976    1\n",
       "         ..\n",
       "18629     1\n",
       "224479    1\n",
       "84932     1\n",
       "138552    1\n",
       "211345    1\n",
       "Name: y_TL, Length: 2049, dtype: category\n",
       "Categories (2, int64): [0, 1]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_input.loc[y_input == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "adffba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fully connected model 2 - using probabilities\n",
    "fc_model_2 = tf.keras.Sequential([tf.keras.layers.Dense(100,activation='tanh',input_shape = (541,)),\n",
    "    tf.keras.layers.Dense(50, activation='tanh'),\n",
    "    tf.keras.layers.Dense(2,activation = 'sigmoid'),\n",
    "    tf.keras.layers.Softmax()\n",
    "    \n",
    "])\n",
    "\n",
    "lrate = 0.005\n",
    "fc_model_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
    "                     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False) ,metrics=['accuracy','FalseNegatives'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f14fb179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 100)               54200     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 102       \n",
      "_________________________________________________________________\n",
      "softmax_2 (Softmax)          (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 59,352\n",
      "Trainable params: 59,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae6bb0d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2710/8858395.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc_model_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2710/4092831646.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, feature, label, val_feature, val_label, epochs, batch_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m                       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                       epochs=epochs)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mtrained_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1146\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1381\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m         \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "trained_weight, trained_bias, epochs, accuracy, val_accuracy, hist = train_model(fc_model_2, X_input, y_input, X_val, y_val, epochs, batch_size)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
